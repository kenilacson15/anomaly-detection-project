{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPreprocessor:\n",
    "    def __init__(self, raw_file_path, processed_dir):\n",
    "        self.raw_file_path = raw_file_path\n",
    "        self.processed_dir = processed_dir\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Loads the raw dataset from CSV.\"\"\"\n",
    "        if not os.path.exists(self.raw_file_path):\n",
    "            raise FileNotFoundError(f\"File not found: {self.raw_file_path}\")\n",
    "        try:\n",
    "            df = pd.read_csv(self.raw_file_path)\n",
    "            print(f\"✅ Loaded raw data with {df.shape[0]} rows and {df.shape[1]} columns.\")\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error loading data: {e}\")\n",
    "            raise\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        \"\"\"\n",
    "        Preprocesses and cleans the dataset:\n",
    "          - Removes duplicate rows.\n",
    "          - Optimizes data types for memory efficiency.\n",
    "          - Imputes missing values (if any) using median for numeric features and mode for categorical features.\n",
    "        \"\"\"\n",
    "        # Remove duplicate rows\n",
    "        initial_count = df.shape[0]\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"✅ Dropped {initial_count - df.shape[0]} duplicate rows.\")\n",
    "\n",
    "        # Optimize data types\n",
    "        try:\n",
    "            df['temperature'] = df['temperature'].astype('float32')\n",
    "            df['pressure'] = df['pressure'].astype('float32')\n",
    "            df['vibration'] = df['vibration'].astype('float32')\n",
    "            df['humidity'] = df['humidity'].astype('float32')\n",
    "            df['faulty'] = df['faulty'].astype('int8')\n",
    "            df['equipment'] = df['equipment'].astype('category')\n",
    "            df['location'] = df['location'].astype('category')\n",
    "            print(\"✅ Optimized data types for memory efficiency.\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error converting data types: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Impute missing values if any\n",
    "        missing = df.isnull().sum()\n",
    "        if missing.any():\n",
    "            print(\"⚠️ Missing values detected. Imputing missing values...\")\n",
    "            # Numeric columns imputed with median\n",
    "            numeric_cols = ['temperature', 'pressure', 'vibration', 'humidity']\n",
    "            for col in numeric_cols:\n",
    "                if df[col].isnull().sum() > 0:\n",
    "                    median_val = df[col].median()\n",
    "                    df[col].fillna(median_val, inplace=True)\n",
    "                    print(f\"   Imputed missing values in '{col}' with median value {median_val}\")\n",
    "\n",
    "            # Categorical columns imputed with mode\n",
    "            categorical_cols = ['equipment', 'location']\n",
    "            for col in categorical_cols:\n",
    "                if df[col].isnull().sum() > 0:\n",
    "                    mode_val = df[col].mode()[0]\n",
    "                    df[col].fillna(mode_val, inplace=True)\n",
    "                    print(f\"   Imputed missing values in '{col}' with mode value {mode_val}\")\n",
    "\n",
    "            # In case 'faulty' has missing values (unlikely)\n",
    "            if df['faulty'].isnull().sum() > 0:\n",
    "                mode_val = df['faulty'].mode()[0]\n",
    "                df['faulty'].fillna(mode_val, inplace=True)\n",
    "                print(f\"   Imputed missing values in 'faulty' with mode value {mode_val}\")\n",
    "        else:\n",
    "            print(\"✅ No missing values found.\")\n",
    "\n",
    "        return df\n",
    "\n",
    "    def save_processed_data(self, df, filename=\"equipment_anomaly_data_processed.csv\"):\n",
    "        \"\"\"Saves the processed dataset to the specified processed folder.\"\"\"\n",
    "        if not os.path.exists(self.processed_dir):\n",
    "            os.makedirs(self.processed_dir)\n",
    "            print(f\"✅ Created processed data directory: {self.processed_dir}\")\n",
    "        processed_file_path = os.path.join(self.processed_dir, filename)\n",
    "        try:\n",
    "            df.to_csv(processed_file_path, index=False)\n",
    "            print(f\"✅ Processed data saved to: {processed_file_path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error saving processed data: {e}\")\n",
    "            raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_file_path = r\"C:\\Users\\Ken Ira Talingting\\Desktop\\anomaly-detection-project\\data\\raw\\equipment_anomaly_data.csv\"\n",
    "processed_dir = r\"C:\\Users\\Ken Ira Talingting\\Desktop\\anomaly-detection-project\\data\\processed\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = DataPreprocessor(raw_file_path, processed_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = preprocessor.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = preprocessor.preprocess(raw_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor.save_processed_data(processed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if processed_df is not None:\n",
    "    display(processed_df.head())  # Display first 5 rows\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
