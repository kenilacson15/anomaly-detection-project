{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing Notebook\n",
    "\n",
    "This notebook demonstrates the data preprocessing pipeline using our custom `DataPreprocessor` class.  \n",
    "We will perform the following steps:\n",
    "1. Load the raw dataset.\n",
    "2. Preprocess the data (remove duplicates, optimize data types, and impute missing values).\n",
    "3. Save the cleaned data for further analysis.\n",
    "\n",
    "Let's get started!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Import our DataPreprocessor class\n",
    "# Adjust the import path based on your project structure.\n",
    "# For example, if the file is located at 'src/data_preprocessor.py':\n",
    "from src.data_preprocessor import DataPreprocessor\n",
    "\n",
    "# Alternatively, if you haven't packaged your source code yet, you could insert the class definition directly here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to the raw data and the directory where processed data will be saved.\n",
    "raw_file_path = r\"C:\\Users\\Ken Ira Talingting\\Desktop\\anomaly-detection-project\\data\\raw\\equipment_anomaly_data.csv\"\n",
    "processed_dir = r\"C:\\Users\\Ken Ira Talingting\\Desktop\\anomaly-detection-project\\data\\processed\"\n",
    "\n",
    "print(\"Raw file path:\", raw_file_path)\n",
    "print(\"Processed data directory:\", processed_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataPreprocessor and load the raw data.\n",
    "preprocessor = DataPreprocessor(raw_file_path, processed_dir)\n",
    "\n",
    "# Load the raw data\n",
    "try:\n",
    "    raw_df = preprocessor.load_data()\n",
    "    print(\"Raw Data Loaded Successfully:\")\n",
    "    display(raw_df.head())\n",
    "except Exception as e:\n",
    "    print(\"Error loading raw data:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing to clean and prepare the data.\n",
    "try:\n",
    "    processed_df = preprocessor.preprocess(raw_df)\n",
    "    print(\"Data Preprocessing Completed Successfully:\")\n",
    "    display(processed_df.head())\n",
    "except Exception as e:\n",
    "    print(\"Error during preprocessing:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed data to the specified directory.\n",
    "try:\n",
    "    preprocessor.save_processed_data(processed_df)\n",
    "    print(\"Processed data saved successfully!\")\n",
    "except Exception as e:\n",
    "    print(\"Error saving processed data:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the processed file exists in the target directory.\n",
    "processed_file_path = os.path.join(processed_dir, \"equipment_anomaly_data_processed.csv\")\n",
    "if os.path.exists(processed_file_path):\n",
    "    print(\"✅ Processed file exists:\", processed_file_path)\n",
    "else:\n",
    "    print(\"❌ Processed file not found!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
