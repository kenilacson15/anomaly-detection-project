{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Isolation Forest Model Training for Anomaly Detection\n",
    "\n",
    "**Objective:**  \n",
    "Train an Isolation Forest model on the engineered equipment anomaly dataset and evaluate its performance. The model will be saved along with evaluation metrics and visualizations for production use.\n",
    "\n",
    "---\n",
    "\n",
    "## Table of Contents\n",
    "1. [Configuration & Setup](#configuration)\n",
    "2. [Data Loading & Preprocessing](#data)\n",
    "3. [Model Training](#training)\n",
    "4. [Model Evaluation](#evaluation)\n",
    "5. [Visualization of Results](#visualization)\n",
    "6. [Performance Tuning & Future Improvements](#tuning)\n",
    "7. [Conclusion](#conclusion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# <a id=\"configuration\"></a>\n",
    "# ## 1. Configuration & Setup\n",
    "\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, RocCurveDisplay\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from joblib import dump\n",
    "\n",
    "# Configuration Parameters\n",
    "SEED = 42\n",
    "DATA_PATH = r\"C:\\Users\\Ken Ira Talingting\\Desktop\\anomaly-detection-project\\data\\processed\\equipment_anomaly_data_feature_engineered.csv\"\n",
    "RESULTS_DIR = r\"C:\\Users\\Ken Ira Talingting\\Desktop\\anomaly-detection-project\\data\\processed_results\"\n",
    "MODEL_PATH = os.path.join(RESULTS_DIR, \"isolation_forest_model.joblib\")\n",
    "METRICS_PATH = os.path.join(RESULTS_DIR, \"evaluation_metrics.json\")\n",
    "\n",
    "# Ensure results directory exists\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(SEED)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# <a id=\"data\"></a>\n",
    "## 2. Data Loading & Preprocessing\n",
    "\n",
    "In this section, we load the dataset, separate features and target, and split the data into training and test sets using stratification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "julia"
    }
   },
   "outputs": [],
   "source": [
    "def load_and_preprocess_data():\n",
    "    \"\"\"\n",
    "    Load and preprocess the dataset.\n",
    "    \n",
    "    Returns:\n",
    "        X_train, X_test, y_train, y_test: Split and preprocessed data.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(DATA_PATH)\n",
    "    \n",
    "    # Separate features and target ('faulty' column)\n",
    "    X = df.drop(columns=['faulty'])\n",
    "    y = df['faulty'].astype(int)\n",
    "    \n",
    "    # Split the data with stratification to maintain class distribution\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=SEED\n",
    "    )\n",
    "    \n",
    "    # Optionally, you can scale features here if needed:\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = pd.DataFrame(scaler.fit_transform(X_train), columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(scaler.transform(X_test), columns=X_test.columns)\n",
    "    \n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n",
    "\n",
    "# Load data\n",
    "X_train, X_test, y_train, y_test = load_and_preprocess_data()\n",
    "print(\"Data loaded and preprocessed:\")\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# <a id=\"training\"></a>\n",
    "## 3. Model Training\n",
    "\n",
    "We train an Isolation Forest model. The contamination parameter is estimated from the training data to reflect the anomaly rate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, contamination):\n",
    "    \"\"\"\n",
    "    Train and return the Isolation Forest model.\n",
    "    \n",
    "    Parameters:\n",
    "        X_train (DataFrame): Training features.\n",
    "        contamination (float): Estimated anomaly rate.\n",
    "        \n",
    "    Returns:\n",
    "        model: Trained IsolationForest model.\n",
    "    \"\"\"\n",
    "    model = IsolationForest(\n",
    "        n_estimators=200,\n",
    "        max_samples='auto',\n",
    "        contamination=contamination,\n",
    "        max_features=1.0,\n",
    "        random_state=SEED,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    model.fit(X_train)\n",
    "    return model\n",
    "\n",
    "# Estimate contamination from training labels (if available)\n",
    "contamination_rate = y_train.mean()\n",
    "print(f\"Estimated contamination rate: {contamination_rate:.4f}\")\n",
    "\n",
    "# Train the model\n",
    "model = train_model(X_train, contamination_rate)\n",
    "\n",
    "# Save the model for production use\n",
    "dump(model, MODEL_PATH)\n",
    "print(f\"Model saved to {MODEL_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# <a id=\"evaluation\"></a>\n",
    "## 4. Model Evaluation\n",
    "\n",
    "Here, we evaluate the model using:\n",
    "- Binary predictions (0 = normal, 1 = anomaly)\n",
    "- Classification metrics (report and confusion matrix)\n",
    "- ROC AUC calculation\n",
    "\n",
    "We also compute anomaly scores from the decision function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    Evaluate the model and compute evaluation metrics.\n",
    "    \n",
    "    Returns:\n",
    "        metrics (dict): Evaluation metrics including classification report, confusion matrix, and ROC AUC.\n",
    "    \"\"\"\n",
    "    # Generate predictions and convert -1/1 to 1/0 format\n",
    "    test_pred = model.predict(X_test)\n",
    "    test_pred_binary = np.where(test_pred == -1, 1, 0)\n",
    "    \n",
    "    # Calculate anomaly scores (negative decision function; higher means more anomalous)\n",
    "    scores = -model.decision_function(X_test)\n",
    "    \n",
    "    # Compute metrics\n",
    "    report = classification_report(y_test, test_pred_binary, output_dict=True)\n",
    "    cm = confusion_matrix(y_test, test_pred_binary)\n",
    "    \n",
    "    # Compute ROC AUC\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, scores)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    return {\n",
    "        'classification_report': report,\n",
    "        'confusion_matrix': cm.tolist(),\n",
    "        'roc_auc': roc_auc,\n",
    "        'fpr': fpr.tolist(),\n",
    "        'tpr': tpr.tolist(),\n",
    "        'scores': scores  # Return scores for visualization\n",
    "    }\n",
    "\n",
    "metrics = evaluate_model(model, X_test, y_test)\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(classification_report(y_test, np.where(model.predict(X_test) == -1, 1, 0)))\n",
    "print(f\"ROC AUC Score: {metrics['roc_auc']:.4f}\")\n",
    "\n",
    "# Save evaluation metrics to JSON\n",
    "with open(METRICS_PATH, 'w') as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "print(f\"Evaluation metrics saved to {METRICS_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "html"
    }
   },
   "outputs": [],
   "source": [
    "# <a id=\"visualization\"></a>\n",
    "## 5. Visualization of Results\n",
    "\n",
    "We generate visualizations for:\n",
    "- Confusion Matrix\n",
    "- ROC Curve\n",
    "- Anomaly Score Distribution\n",
    "\n",
    "These plots help understand model performance and decision boundaries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_results(metrics, y_test, scores):\n",
    "    \"\"\"\n",
    "    Generate and save evaluation visualizations.\n",
    "    \"\"\"\n",
    "    # Confusion Matrix Visualization\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(metrics['confusion_matrix'], annot=True, fmt='d',\n",
    "                cmap='Blues', cbar=False)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'confusion_matrix.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # ROC Curve Visualization\n",
    "    RocCurveDisplay(fpr=metrics['fpr'], tpr=metrics['tpr'], roc_auc=metrics['roc_auc']).plot()\n",
    "    plt.title('ROC Curve')\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'roc_curve.png'))\n",
    "    plt.close()\n",
    "    \n",
    "    # Anomaly Score Distribution Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    # Separate scores for normal and anomalous samples based on true labels\n",
    "    sns.kdeplot(scores[y_test == 0], label='Normal', fill=True)\n",
    "    sns.kdeplot(scores[y_test == 1], label='Anomaly', fill=True)\n",
    "    plt.title('Anomaly Score Distribution')\n",
    "    plt.xlabel('Anomaly Score')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(RESULTS_DIR, 'score_distribution.png'))\n",
    "    plt.close()\n",
    "\n",
    "# Visualize and save results\n",
    "visualize_results(metrics, y_test.values, metrics['scores'])\n",
    "print(\"Visualizations saved to the results directory.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# <a id=\"tuning\"></a>\n",
    "## 6. Performance Tuning & Future Improvements\n",
    "\n",
    "**Performance Tuning Suggestions:**\n",
    "- **Hyperparameter Optimization:**  \n",
    "  Consider using GridSearchCV for parameters like:\n",
    "  - `n_estimators`: [100, 200, 500]\n",
    "  - `max_samples`: [0.5, 0.8, 'auto']\n",
    "  - `max_features`: [0.5, 0.8, 1.0]\n",
    "  - `contamination`: [calculated_rate ± 0.01]\n",
    "- **Feature Analysis:**  \n",
    "  Use SHAP or feature importance methods to understand which features are most critical.\n",
    "- **Ensemble Methods:**  \n",
    "  Consider combining Isolation Forest with other algorithms (e.g., LOF, OCSVM) for a voting ensemble.\n",
    "- **Threshold Optimization:**  \n",
    "  Optimize the decision threshold based on business requirements, balancing precision and recall.\n",
    "\n",
    "**Future Improvements:**\n",
    "- Implement real-time monitoring and model drift detection.\n",
    "- Incorporate contextual or temporal features to enhance detection.\n",
    "- Explore cost-sensitive learning to minimize false positives/negatives.\n",
    "- Package the solution as an API endpoint for real-time inference.\n",
    "\n",
    "---\n",
    "\n",
    "```markdown\n",
    "# <a id=\"conclusion\"></a>\n",
    "## 7. Conclusion\n",
    "\n",
    "In this notebook, we developed a production-ready Isolation Forest model for anomaly detection on an equipment dataset. We followed best practices in data preprocessing, model training, evaluation, and result visualization. The model, along with evaluation metrics and visualizations, has been saved for future deployment.\n",
    "\n",
    "**Next Steps:**  \n",
    "- Perform hyperparameter tuning to further optimize model performance.  \n",
    "- Extend the pipeline with automated monitoring and periodic retraining for production.\n",
    "\n",
    "---\n",
    "\n",
    "*End of Notebook*\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
